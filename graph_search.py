"""
HuggingGraph æ£€ç´¢å·¥å…·
æ”¯æŒå¯¹å›¾ç»“æ„è¿›è¡Œå„ç§æ£€ç´¢æ“ä½œ
"""

import networkx as nx
from networkx.drawing.nx_pydot import read_dot
import pickle
import os
from typing import List, Set, Optional


class HuggingGraphSearcher:
    """HuggingGraph å›¾æ£€ç´¢ç±»"""
    
    def __init__(self, dot_file: str = "HuggingGraph.dot", cache_file: str = "graph_cache.pkl"):
        """
        åˆå§‹åŒ–å›¾æ£€ç´¢å™¨
        
        Args:
            dot_file: DOT æ–‡ä»¶è·¯å¾„
            cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºåŠ é€Ÿåç»­åŠ è½½ï¼‰
        """
        self.dot_file = dot_file
        self.cache_file = cache_file
        self.G = None
        self._load_graph()
    
    def _load_graph(self):
        """åŠ è½½å›¾ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
        if os.path.exists(self.cache_file):
            print(f"ä»ç¼“å­˜åŠ è½½å›¾: {self.cache_file}")
            with open(self.cache_file, 'rb') as f:
                self.G = pickle.load(f)
            print(f"âœ… å›¾å·²åŠ è½½: {self.G.number_of_nodes():,} ä¸ªèŠ‚ç‚¹, {self.G.number_of_edges():,} æ¡è¾¹")
        else:
            print(f"æ­£åœ¨ä» DOT æ–‡ä»¶åŠ è½½å›¾: {self.dot_file}")
            print("è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´...")
            self.G = read_dot(self.dot_file)
            # è½¬æ¢ä¸ºæœ‰å‘å›¾ï¼ˆå¦‚æœè¿˜ä¸æ˜¯ï¼‰
            if not isinstance(self.G, nx.DiGraph):
                self.G = self.G.to_directed()
            
            print(f"âœ… å›¾å·²åŠ è½½: {self.G.number_of_nodes():,} ä¸ªèŠ‚ç‚¹, {self.G.number_of_edges():,} æ¡è¾¹")
            
            # ä¿å­˜ç¼“å­˜
            print(f"æ­£åœ¨ä¿å­˜ç¼“å­˜åˆ°: {self.cache_file}")
            with open(self.cache_file, 'wb') as f:
                pickle.dump(self.G, f)
            print("âœ… ç¼“å­˜å·²ä¿å­˜")
    
    def search_node(self, keyword: str, limit: int = 10) -> List[str]:
        """
        æœç´¢åŒ…å«å…³é”®è¯çš„èŠ‚ç‚¹
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            åŒ¹é…çš„èŠ‚ç‚¹åˆ—è¡¨
        """
        keyword_lower = keyword.lower()
        matches = [node for node in self.G.nodes() 
                  if keyword_lower in str(node).lower()]
        return matches[:limit]
    
    def get_node_neighbors(self, node: str, direction: str = "both") -> dict:
        """
        è·å–èŠ‚ç‚¹çš„é‚»å±…
        
        Args:
            node: èŠ‚ç‚¹åç§°
            direction: "in" (å…¥è¾¹), "out" (å‡ºè¾¹), "both" (åŒå‘)
            
        Returns:
            åŒ…å«å‰é©±å’Œåç»§çš„å­—å…¸
        """
        if node not in self.G:
            return {"error": f"èŠ‚ç‚¹ '{node}' ä¸å­˜åœ¨"}
        
        result = {
            "node": node,
            "in_degree": self.G.in_degree(node),
            "out_degree": self.G.out_degree(node),
        }
        
        if direction in ["in", "both"]:
            result["predecessors"] = list(self.G.predecessors(node))
        
        if direction in ["out", "both"]:
            result["successors"] = list(self.G.successors(node))
        
        return result
    
    def find_path(self, source: str, target: str) -> Optional[List[str]]:
        """
        æŸ¥æ‰¾ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„æœ€çŸ­è·¯å¾„
        
        Args:
            source: æºèŠ‚ç‚¹
            target: ç›®æ ‡èŠ‚ç‚¹
            
        Returns:
            è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        if source not in self.G:
            return None
        if target not in self.G:
            return None
        
        try:
            path = nx.shortest_path(self.G, source, target)
            return path
        except nx.NetworkXNoPath:
            return None
    
    def forward_trace(self, node: str, max_depth: int = 3) -> dict:
        """
        å‰å‘è¿½è¸ªï¼šæŸ¥æ‰¾ä»è¯¥èŠ‚ç‚¹å‡ºå‘çš„æ‰€æœ‰ä¸‹æ¸¸èŠ‚ç‚¹ï¼ˆä¾èµ–é“¾ï¼‰
        
        Args:
            node: èµ·å§‹èŠ‚ç‚¹
            max_depth: æœ€å¤§è¿½è¸ªæ·±åº¦
            
        Returns:
            æŒ‰æ·±åº¦ç»„ç»‡çš„èŠ‚ç‚¹å­—å…¸
        """
        if node not in self.G:
            return {"error": f"èŠ‚ç‚¹ '{node}' ä¸å­˜åœ¨"}
        
        visited = set()
        result = {0: [node]}
        visited.add(node)
        
        current_level = [node]
        
        for depth in range(1, max_depth + 1):
            next_level = []
            for n in current_level:
                for successor in self.G.successors(n):
                    if successor not in visited:
                        visited.add(successor)
                        next_level.append(successor)
            
            if not next_level:
                break
            
            result[depth] = next_level
            current_level = next_level
        
        return result
    
    def backward_trace(self, node: str, max_depth: int = 3) -> dict:
        """
        åå‘è¿½è¸ªï¼šæŸ¥æ‰¾æŒ‡å‘è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰ä¸Šæ¸¸èŠ‚ç‚¹ï¼ˆä¾èµ–é“¾ï¼‰
        
        Args:
            node: èµ·å§‹èŠ‚ç‚¹
            max_depth: æœ€å¤§è¿½è¸ªæ·±åº¦
            
        Returns:
            æŒ‰æ·±åº¦ç»„ç»‡çš„èŠ‚ç‚¹å­—å…¸
        """
        if node not in self.G:
            return {"error": f"èŠ‚ç‚¹ '{node}' ä¸å­˜åœ¨"}
        
        visited = set()
        result = {0: [node]}
        visited.add(node)
        
        current_level = [node]
        
        for depth in range(1, max_depth + 1):
            next_level = []
            for n in current_level:
                for predecessor in self.G.predecessors(n):
                    if predecessor not in visited:
                        visited.add(predecessor)
                        next_level.append(predecessor)
            
            if not next_level:
                break
            
            result[depth] = next_level
            current_level = next_level
        
        return result
    
    def get_subgraph(self, node: str, depth: int = 2) -> nx.DiGraph:
        """
        è·å–ä»¥æŸä¸ªèŠ‚ç‚¹ä¸ºä¸­å¿ƒçš„å­å›¾
        
        Args:
            node: ä¸­å¿ƒèŠ‚ç‚¹
            depth: å­å›¾æ·±åº¦
            
        Returns:
            å­å›¾å¯¹è±¡
        """
        if node not in self.G:
            return nx.DiGraph()
        
        nodes_to_include = {node}
        current_nodes = {node}
        
        for _ in range(depth):
            next_nodes = set()
            for n in current_nodes:
                next_nodes.update(self.G.successors(n))
                next_nodes.update(self.G.predecessors(n))
            nodes_to_include.update(next_nodes)
            current_nodes = next_nodes
        
        return self.G.subgraph(nodes_to_include).copy()
    
    def get_statistics(self) -> dict:
        """è·å–å›¾çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "nodes": self.G.number_of_nodes(),
            "edges": self.G.number_of_edges(),
            "is_directed": self.G.is_directed(),
            "density": nx.density(self.G),
        }


# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    print("=" * 60)
    print("HuggingGraph æ£€ç´¢å·¥å…·")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    searcher = HuggingGraphSearcher()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = searcher.get_statistics()
    print(f"\nğŸ“Š å›¾ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  èŠ‚ç‚¹æ•°: {stats['nodes']:,}")
    print(f"  è¾¹æ•°: {stats['edges']:,}")
    print(f"  å›¾å¯†åº¦: {stats['density']:.6f}")
    
    # ç¤ºä¾‹1: æœç´¢èŠ‚ç‚¹
    print(f"\nğŸ” ç¤ºä¾‹1: æœç´¢åŒ…å« 'llama' çš„èŠ‚ç‚¹")
    llama_nodes = searcher.search_node("llama", limit=5)
    for i, node in enumerate(llama_nodes, 1):
        print(f"  {i}. {node}")
    
    # ç¤ºä¾‹2: è·å–èŠ‚ç‚¹é‚»å±…
    if llama_nodes:
        print(f"\nğŸ“Œ ç¤ºä¾‹2: è·å–èŠ‚ç‚¹ '{llama_nodes[0]}' çš„é‚»å±…")
        neighbors = searcher.get_node_neighbors(llama_nodes[0], direction="both")
        print(f"  å…¥åº¦: {neighbors['in_degree']}, å‡ºåº¦: {neighbors['out_degree']}")
        if 'predecessors' in neighbors and neighbors['predecessors']:
            print(f"  å‰é©±èŠ‚ç‚¹ (å‰5ä¸ª): {neighbors['predecessors'][:5]}")
        if 'successors' in neighbors and neighbors['successors']:
            print(f"  åç»§èŠ‚ç‚¹ (å‰5ä¸ª): {neighbors['successors'][:5]}")
    
    # ç¤ºä¾‹3: å‰å‘è¿½è¸ª
    if llama_nodes:
        print(f"\nâ¡ï¸  ç¤ºä¾‹3: å‰å‘è¿½è¸ª '{llama_nodes[0]}' (æ·±åº¦=2)")
        forward = searcher.forward_trace(llama_nodes[0], max_depth=2)
        for depth, nodes in forward.items():
            if isinstance(nodes, list):
                print(f"  æ·±åº¦ {depth}: {len(nodes)} ä¸ªèŠ‚ç‚¹")
                if nodes:
                    print(f"    ç¤ºä¾‹: {nodes[0]}")
    
    # ç¤ºä¾‹4: åå‘è¿½è¸ª
    if llama_nodes:
        print(f"\nâ¬…ï¸  ç¤ºä¾‹4: åå‘è¿½è¸ª '{llama_nodes[0]}' (æ·±åº¦=2)")
        backward = searcher.backward_trace(llama_nodes[0], max_depth=2)
        for depth, nodes in backward.items():
            if isinstance(nodes, list):
                print(f"  æ·±åº¦ {depth}: {len(nodes)} ä¸ªèŠ‚ç‚¹")
                if nodes:
                    print(f"    ç¤ºä¾‹: {nodes[0]}")
    
    print(f"\nâœ… æ£€ç´¢å·¥å…·å·²å°±ç»ªï¼")
    print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print(f"  from graph_search import HuggingGraphSearcher")
    print(f"  searcher = HuggingGraphSearcher()")
    print(f"  # ç„¶åè°ƒç”¨å„ç§æ£€ç´¢æ–¹æ³•")

